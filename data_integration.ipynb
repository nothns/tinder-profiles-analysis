{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"raw_data/profiles_2021-11-10.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"__v\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"__v\", \"messages\", \"swipes\", \"userId\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a sample of JSON for exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = json.loads(df.iloc[1].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"test.json\", \"w\")\n",
    "  \n",
    "json.dump(test, out_file)\n",
    "  \n",
    "out_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening and melting df_appOpens, df_messagesReceived, df_messagesSent, df_matches, df_swipeLikes, df_swipePasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_process = ['appOpens', 'messagesReceived', 'messagesSent', 'matches', 'swipeLikes', 'swipePasses']\n",
    "df_dict = {}\n",
    "\n",
    "for col in cols_to_process:\n",
    "    df_temp = df[[\"_id\", col]]\n",
    "    df_temp = pd.concat([df_temp.drop(col, axis=1), df_temp[col].apply(pd.Series)], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    df_temp = pd.melt(df_temp, id_vars='_id', var_name='date', value_name='value')\n",
    "    df_temp.dropna(subset=['value'], inplace=True)\n",
    "    df_temp.sort_values(by=['_id', 'date'], inplace=True)\n",
    "    # Store the reshaped DataFrame in the dictionary using the column name as the key\n",
    "    df_dict[col] = df_temp\n",
    "\n",
    "df_appOpens = df_dict['appOpens']\n",
    "df_messagesReceived = df_dict['messagesReceived']\n",
    "df_messagesSent = df_dict['messagesSent']\n",
    "df_matches = df_dict['matches']\n",
    "df_swipeLikes = df_dict['swipeLikes']\n",
    "df_swipePasses = df_dict['swipePasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_appOpens = df[[\"_id\", \"appOpens\"]]\n",
    "# df_appOpens = pd.concat([df_appOpens.drop(\"appOpens\", axis=1), df_appOpens[\"appOpens\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"appOpens\", axis=1, inplace=True)\n",
    "# df_appOpens = pd.melt(df_appOpens, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_appOpens.dropna(subset=['value'], inplace=True)\n",
    "# df_appOpens.sort_values(by=['_id', 'date'], inplace=True)\n",
    "# df_matches = df[[\"_id\", \"matches\"]]\n",
    "# df_matches = pd.concat([df_matches.drop(\"matches\", axis=1), df_matches[\"matches\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"matches\", axis=1, inplace=True)\n",
    "# df_matches = pd.melt(df_matches, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_matches.dropna(subset=['value'], inplace=True)\n",
    "# df_matches.sort_values(by=['_id', 'date'], inplace=True)\n",
    "# df_messagesReceived = df[[\"_id\", \"messagesReceived\"]]\n",
    "# df_messagesReceived = pd.concat([df_messagesReceived.drop(\"messagesReceived\", axis=1), df_messagesReceived[\"messagesReceived\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"messagesReceived\", axis=1, inplace=True)\n",
    "# df_messagesReceived = pd.melt(df_messagesReceived, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_messagesReceived.dropna(subset=['value'], inplace=True)\n",
    "# df_messagesReceived.sort_values(by=['_id', 'date'], inplace=True)\n",
    "# df_messagesSent = df[[\"_id\", \"messagesSent\"]]\n",
    "# df_messagesSent = pd.concat([df_messagesSent.drop(\"messagesSent\", axis=1), df_messagesSent[\"messagesSent\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"messagesSent\", axis=1, inplace=True)\n",
    "# df_messagesSent = pd.melt(df_messagesSent, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_messagesSent.dropna(subset=['value'], inplace=True)\n",
    "# df_messagesSent.sort_values(by=['_id', 'date'], inplace=True)\n",
    "# df_swipeLikes = df[[\"_id\", \"swipeLikes\"]]\n",
    "# df_swipeLikes = pd.concat([df_swipeLikes.drop(\"swipeLikes\", axis=1), df_swipeLikes[\"swipeLikes\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"swipeLikes\", axis=1, inplace=True)\n",
    "# df_swipeLikes = pd.melt(df_swipeLikes, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_swipeLikes.dropna(subset=['value'], inplace=True)\n",
    "# df_swipeLikes.sort_values(by=['_id', 'date'], inplace=True)\n",
    "# df_swipePasses = df[[\"_id\", \"swipePasses\"]]\n",
    "# df_swipePasses = pd.concat([df_swipePasses.drop(\"swipePasses\", axis=1), df_swipePasses[\"swipePasses\"].apply(pd.Series)], axis=1)\n",
    "# df.drop(\"swipePasses\", axis=1, inplace=True)\n",
    "# df_swipePasses = pd.melt(df_swipePasses, id_vars='_id', var_name='date', value_name='value')\n",
    "# df_swipePasses.dropna(subset=['value'], inplace=True)\n",
    "# df_swipePasses.sort_values(by=['_id', 'date'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing df_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations = df[[\"_id\", \"conversations\"]]\n",
    "df_conversations = pd.concat([df_conversations.drop(\"conversations\", axis=1), df_conversations[\"conversations\"].apply(pd.Series)], axis=1)\n",
    "df.drop(\"conversations\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up list format for MySQL\n",
    "\n",
    "main = pd.concat([df.drop([\"conversationsMeta\", \"user\"], axis=1), df[\"conversationsMeta\"].apply(pd.Series), df[\"user\"].apply(pd.Series)], axis=1)\n",
    "df_export = main.copy()\n",
    "df_export['jobs'] = df_export['jobs'].apply(lambda x: str(x))\n",
    "df_export['schools'] = df_export['schools'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to sql\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "connection_string = \"mysql+mysqlconnector://root:food99@127.0.0.1:3306/tinder_profiles_analysis\"\n",
    "engine = create_engine(connection_string, echo=True)\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending users tables to database\n",
    "\n",
    "df_export.to_sql(name='users_raw', con=con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending other tables to database\n",
    "\n",
    "dfs = [df_appOpens, df_messagesReceived, df_messagesSent, df_matches, df_swipeLikes, df_swipePasses]\n",
    "table_names = ['appOpens', 'messagesReceived', 'messagesSent', 'matches', 'swipeLikes', 'swipePasses']\n",
    "\n",
    "for df, table_name in zip(dfs, table_names):\n",
    "    df.to_sql(name=table_name+'_raw', con=con, if_exists='replace', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking jobs and schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main[\"jobs\"].apply(lambda x: len(x)).unique()\n",
    "\n",
    "# This tells us the maximum number of jobs is one, so jobs will be flattened (processed in sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main[\"schools\"] = main[\"schools\"].apply(lambda x: [] if type(x) == float else x)\n",
    "main[\"schools\"].apply(lambda x: type(x)).unique()\n",
    "main[\"schools\"].apply(lambda x: len(x)).unique()\n",
    "\n",
    "# This tells us there are people with more than one school, but there are only three, so we will ignore and just take their first school (processed in sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking df_conversations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations_m = pd.melt(df_conversations, id_vars='_id', var_name='conversation_number', value_name='messages')\n",
    "df_conversations_m.dropna(subset=['messages'], inplace=True)\n",
    "df_conversations_m.sort_values(by=['_id', 'conversation_number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for index, row in df_conversations_m.iterrows():\n",
    "    for i in range(len(row['messages']['messages'])):\n",
    "        temp = [row[\"_id\"], row[\"conversation_number\"]]\n",
    "        try:\n",
    "            temp.append(row['messages']['messages'][i]['message'])\n",
    "        except:\n",
    "            temp.append(np.NAN)\n",
    "        try:\n",
    "            temp.append(row['messages']['messages'][i]['sent_date'])\n",
    "        except:\n",
    "            temp.append(np.NAN)\n",
    "        df_list.append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages_l = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_messages_l.columns = ['_id', 'conversation_number', 'message', 'time_sent']\n",
    "df_messages_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages_l.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending conversations tables to database\n",
    "\n",
    "chunksize = 100000  \n",
    "for i in range(0, df_messages_l.shape[0], chunksize):\n",
    "    df_messages_l.iloc[i:i+chunksize].to_sql(name=\"conversations_raw\", con=con, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
